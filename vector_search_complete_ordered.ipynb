{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Vector Search Tutorial\n",
    "## Step-by-step learning with Airbnb dataset\n",
    "\n",
    "Run cells in order: 1 â†’ 2 â†’ 3 â†’ ... â†’ 17\n",
    "\n",
    "**What we'll build:**\n",
    "1. Load Airbnb dataset with embeddings (Cells 1-4)\n",
    "2. Create Pydantic models for data validation (Cells 5-8)\n",
    "3. Connect to MongoDB Atlas and insert data (Cells 9-10)\n",
    "4. Create vector search index (Cells 11-12)\n",
    "5. Implement vector search (Cells 12-14)\n",
    "6. Build GPT-powered recommendation system (Cells 15-17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… All imports loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API Key: Found\n",
      "âœ… MongoDB URI: Found\n",
      "âœ… HuggingFace Token: Found\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load API keys\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\") \n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "print(\"âœ… OpenAI API Key:\", \"Found\" if OPENAI_API_KEY else \"âŒ Missing\")\n",
    "print(\"âœ… MongoDB URI:\", \"Found\" if MONGO_URI else \"âŒ Missing\")  \n",
    "print(\"âœ… HuggingFace Token:\", \"Found\" if HF_TOKEN else \"âŒ Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading Airbnb dataset...\n",
      "âœ… Loaded 20 records\n",
      "ğŸ“Š Shape: (20, 43)\n",
      "ğŸ”— Embeddings: 1536 dimensions\n",
      "\n",
      "ğŸ  Sample: Ribeira Charming Duplex - $80 - 8 guests\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load dataset\n",
    "print(\"ğŸ”„ Loading Airbnb dataset...\")\n",
    "\n",
    "dataset = load_dataset(\"MongoDB/airbnb_embeddings\", streaming=True, split=\"train\")\n",
    "dataset = dataset.take(20)\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(f\"âœ… Loaded {len(dataset_df)} records\")\n",
    "print(f\"ğŸ“Š Shape: {dataset_df.shape}\")\n",
    "print(f\"ğŸ”— Embeddings: {len(dataset_df.iloc[0]['text_embeddings'])} dimensions\")\n",
    "\n",
    "# Show sample\n",
    "sample = dataset_df.iloc[0]\n",
    "print(f\"\\nğŸ  Sample: {sample['name']} - ${sample['price']} - {sample['accommodates']} guests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” How I identify main vs nested structures:\n",
      "\n",
      "ğŸ“Š Field types:\n",
      "  _id             | int64    | 10006546...\n",
      "  name            | str      | Ribeira Charming Duplex...\n",
      "  price           | int64    | 80...\n",
      "  host            | dict     | dict with 16 keys: ['host_id', 'host_url', 'host_name']...\n",
      "  address         | dict     | dict with 7 keys: ['street', 'suburb', 'government_area']...\n",
      "  text_embeddings | list     | list with 1536 items\n",
      "\n",
      "ğŸ’¡ Pattern:\n",
      "  - Simple types (str, int) = main fields\n",
      "  - dict type = needs separate Pydantic model\n",
      "  - list of floats = embeddings for vector search\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Analyze data structure\n",
    "print(\"ğŸ” How I identify main vs nested structures:\\n\")\n",
    "\n",
    "sample = dataset_df.iloc[0]\n",
    "\n",
    "print(\"ğŸ“Š Field types:\")\n",
    "for field_name in ['_id', 'name', 'price', 'host', 'address', 'text_embeddings']:\n",
    "    if field_name in sample:\n",
    "        value = sample[field_name]\n",
    "        field_type = type(value).__name__\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            preview = f\"dict with {len(value)} keys: {list(value.keys())[:3]}...\"\n",
    "        elif isinstance(value, list):\n",
    "            preview = f\"list with {len(value)} items\"\n",
    "        else:\n",
    "            preview = f\"{str(value)[:30]}...\"\n",
    "            \n",
    "        print(f\"  {field_name:15} | {field_type:8} | {preview}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Pattern:\")\n",
    "print(\"  - Simple types (str, int) = main fields\")\n",
    "print(\"  - dict type = needs separate Pydantic model\")\n",
    "print(\"  - list of floats = embeddings for vector search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Creating Pydantic models...\n",
      "âœ… Models created: Host, Location, Address, Listing\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Pydantic models\n",
    "print(\"ğŸ—ï¸ Creating Pydantic models...\")\n",
    "\n",
    "class Host(BaseModel):\n",
    "    host_id: str\n",
    "    host_name: str\n",
    "    host_is_superhost: bool\n",
    "    host_has_profile_pic: bool\n",
    "    host_identity_verified: bool\n",
    "    host_url: Optional[str] = None\n",
    "    host_location: Optional[str] = None\n",
    "    host_about: Optional[str] = None\n",
    "    host_response_time: Optional[str] = None\n",
    "    host_thumbnail_url: Optional[str] = None\n",
    "    host_picture_url: Optional[str] = None\n",
    "    host_response_rate: Optional[int] = None\n",
    "\n",
    "class Location(BaseModel):\n",
    "    type: str\n",
    "    coordinates: List[float]\n",
    "    is_location_exact: bool\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    government_area: str\n",
    "    market: str\n",
    "    country: str\n",
    "    country_code: str\n",
    "    location: Location\n",
    "\n",
    "class Listing(BaseModel):\n",
    "    _id: int\n",
    "    name: str\n",
    "    summary: str\n",
    "    property_type: str\n",
    "    room_type: str\n",
    "    price: int\n",
    "    accommodates: int\n",
    "    host: Host\n",
    "    address: Address\n",
    "    text_embeddings: List[float]\n",
    "    \n",
    "    # Optional fields\n",
    "    listing_url: Optional[str] = None\n",
    "    space: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    neighborhood_overview: Optional[str] = None\n",
    "    notes: Optional[str] = None\n",
    "    transit: Optional[str] = None\n",
    "    access: Optional[str] = None\n",
    "    interaction: Optional[str] = None\n",
    "    house_rules: Optional[str] = None\n",
    "    bed_type: Optional[str] = None\n",
    "    minimum_nights: Optional[int] = None\n",
    "    maximum_nights: Optional[int] = None\n",
    "    cancellation_policy: Optional[str] = None\n",
    "    bedrooms: Optional[float] = 0\n",
    "    beds: Optional[float] = 0\n",
    "    bathrooms: Optional[float] = 0\n",
    "    number_of_reviews: Optional[int] = 0\n",
    "    amenities: Optional[List[str]] = []\n",
    "    security_deposit: Optional[float] = None\n",
    "    cleaning_fee: Optional[float] = None\n",
    "    extra_people: Optional[int] = 0\n",
    "    guests_included: Optional[int] = 1\n",
    "\n",
    "print(\"âœ… Models created: Host, Location, Address, Listing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data cleaner function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Simple data cleaner (handles the NaN/array issue)\n",
    "def clean_record(record):\n",
    "    \"\"\"Clean record - handle NaN values safely\"\"\"\n",
    "    cleaned = {}\n",
    "    for key, value in record.items():\n",
    "        if value is None:\n",
    "            cleaned[key] = None\n",
    "        elif isinstance(value, (dict, list)):\n",
    "            cleaned[key] = value  # Keep complex types as-is\n",
    "        else:\n",
    "            # Only check scalar values for NaN\n",
    "            try:\n",
    "                if pd.isna(value):\n",
    "                    cleaned[key] = None\n",
    "                else:\n",
    "                    cleaned[key] = value\n",
    "            except (ValueError, TypeError):\n",
    "                cleaned[key] = value  # Keep original if check fails\n",
    "    return cleaned\n",
    "\n",
    "print(\"âœ… Data cleaner function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Pydantic with first record...\n",
      "ğŸ‰ SUCCESS! Pydantic validation passed!\n",
      "ğŸ“‹ Name: Ribeira Charming Duplex\n",
      "ğŸ’° Price: $80 (converted to int)\n",
      "ğŸ‘¥ Accommodates: 8\n",
      "ğŸ  Type: House\n",
      "ğŸŒ Location: Porto, Portugal\n",
      "â­ Superhost: False\n",
      "ğŸ”— Embeddings: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test with one record\n",
    "print(\"ğŸ§ª Testing Pydantic with first record...\")\n",
    "\n",
    "sample_record = dataset_df.iloc[0].to_dict()\n",
    "cleaned_record = clean_record(sample_record)\n",
    "\n",
    "try:\n",
    "    listing = Listing(**cleaned_record)\n",
    "    \n",
    "    print(\"ğŸ‰ SUCCESS! Pydantic validation passed!\")\n",
    "    print(f\"ğŸ“‹ Name: {listing.name}\")\n",
    "    print(f\"ğŸ’° Price: ${listing.price} (converted to int)\")\n",
    "    print(f\"ğŸ‘¥ Accommodates: {listing.accommodates}\")\n",
    "    print(f\"ğŸ  Type: {listing.property_type}\")\n",
    "    print(f\"ğŸŒ Location: {listing.address.market}, {listing.address.country}\")\n",
    "    print(f\"â­ Superhost: {listing.host.host_is_superhost}\")\n",
    "    print(f\"ğŸ”— Embeddings: {len(listing.text_embeddings)} dimensions\")\n",
    "    \n",
    "except ValidationError as e:\n",
    "    print(\"âŒ Validation failed:\")\n",
    "    for error in e.errors():\n",
    "        field = ' -> '.join(str(x) for x in error['loc'])\n",
    "        print(f\"  {field}: {error['msg']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"â“ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Processing all 20 records...\n",
      "âœ… 1: Ribeira Charming Duplex... ($80)\n",
      "âœ… 2: Private Room in Bushwick... ($40)\n",
      "âœ… 3: Ocean View Waikiki Marina w/pr... ($115)\n",
      "\n",
      "ğŸ“Š Results:\n",
      "  âœ… Validated: 20 records\n",
      "  âŒ Failed: 0 records\n",
      "\n",
      "ğŸ¯ Ready for MongoDB! Each record has:\n",
      "  - Validated data types\n",
      "  - 1536-dimension embeddings\n",
      "  - Structured host & address info\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Process all records\n",
    "print(\"ğŸ”„ Processing all 20 records...\")\n",
    "\n",
    "validated_listings = []\n",
    "errors = []\n",
    "\n",
    "for i, record in enumerate(dataset_df.to_dict('records')):\n",
    "    try:\n",
    "        cleaned_record = clean_record(record)\n",
    "        listing = Listing(**cleaned_record)\n",
    "        validated_listings.append(listing.dict())\n",
    "        \n",
    "        if i < 3:\n",
    "            print(f\"âœ… {i+1}: {listing.name[:30]}... (${listing.price})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append((i, str(e)))\n",
    "        print(f\"âŒ {i+1}: Failed\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Results:\")\n",
    "print(f\"  âœ… Validated: {len(validated_listings)} records\")\n",
    "print(f\"  âŒ Failed: {len(errors)} records\")\n",
    "\n",
    "if validated_listings:\n",
    "    print(\"\\nğŸ¯ Ready for MongoDB! Each record has:\")\n",
    "    print(\"  - Validated data types\")\n",
    "    print(\"  - 1536-dimension embeddings\")\n",
    "    print(\"  - Structured host & address info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Setting up MongoDB Atlas connection...\n",
      "âœ… Connection to MongoDB Atlas successful!\n",
      "ğŸ“‹ Database: airbnb_dataset\n",
      "ğŸ“‹ Collection: listings_reviews\n",
      "ğŸ¯ Ready to insert 20 records!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: MongoDB Atlas Connection\n",
    "print(\"ğŸ”Œ Setting up MongoDB Atlas connection...\")\n",
    "\n",
    "# Database and collection names\n",
    "database_name = \"airbnb_dataset\"\n",
    "collection_name = \"listings_reviews\"\n",
    "\n",
    "def get_mongo_client(mongo_uri):\n",
    "    \"\"\"Establish connection to MongoDB Atlas\"\"\"\n",
    "    client = MongoClient(mongo_uri, appname=\"devrel.deeplearningai.lesson1.python\")\n",
    "    print(\"âœ… Connection to MongoDB Atlas successful!\")\n",
    "    return client\n",
    "\n",
    "if not MONGO_URI:\n",
    "    print(\"âŒ MONGO_URI not set in environment variables\")\n",
    "else:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = get_mongo_client(MONGO_URI)\n",
    "    \n",
    "    # Get database and collection\n",
    "    db = mongo_client.get_database(database_name)\n",
    "    collection = db.get_collection(collection_name)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Database: {database_name}\")\n",
    "    print(f\"ğŸ“‹ Collection: {collection_name}\")\n",
    "    print(f\"ğŸ¯ Ready to insert {len(validated_listings)} records!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Inserting validated data into MongoDB...\n",
      "ğŸ—‘ï¸ Clearing existing data...\n",
      "Deleted 20 existing records\n",
      "ğŸ“¥ Inserting 20 records...\n",
      "âœ… Successfully inserted 20 records!\n",
      "ğŸ¯ Collection now has 20 documents\n",
      "\n",
      "ğŸ“‹ Sample document structure:\n",
      "  - ID: 68de8b5b53eb7044f9e73371\n",
      "  - Name: Ribeira Charming Duplex\n",
      "  - Price: $80\n",
      "  - Embeddings: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Insert Data into MongoDB\n",
    "print(\"ğŸ’¾ Inserting validated data into MongoDB...\")\n",
    "\n",
    "if MONGO_URI and validated_listings:\n",
    "    # Clear any existing data (optional - be careful!)\n",
    "    print(\"ğŸ—‘ï¸ Clearing existing data...\")\n",
    "    result = collection.delete_many({})\n",
    "    print(f\"Deleted {result.deleted_count} existing records\")\n",
    "    \n",
    "    # Insert our validated listings\n",
    "    print(f\"ğŸ“¥ Inserting {len(validated_listings)} records...\")\n",
    "    insert_result = collection.insert_many(validated_listings)\n",
    "    \n",
    "    print(f\"âœ… Successfully inserted {len(insert_result.inserted_ids)} records!\")\n",
    "    print(f\"ğŸ¯ Collection now has {collection.count_documents({})} documents\")\n",
    "    \n",
    "    # Show a sample document\n",
    "    sample_doc = collection.find_one()\n",
    "    if sample_doc:\n",
    "        print(f\"\\nğŸ“‹ Sample document structure:\")\n",
    "        print(f\"  - ID: {sample_doc['_id']}\")\n",
    "        print(f\"  - Name: {sample_doc['name']}\")\n",
    "        print(f\"  - Price: ${sample_doc['price']}\")\n",
    "        print(f\"  - Embeddings: {len(sample_doc['text_embeddings'])} dimensions\")\n",
    "else:\n",
    "    print(\"âŒ Cannot insert - missing MONGO_URI or no validated listings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Vector Search Index\n",
    "\n",
    "**What is a Vector Search Index?**\n",
    "A vector search index is a special data structure that enables fast similarity searches through high-dimensional vectors (our embeddings).\n",
    "\n",
    "**Key Components:**\n",
    "- **Field**: `text_embeddings` (our 1536-dimension vectors)\n",
    "- **Dimensions**: 1536 (matches OpenAI's text-embedding-3-small model)\n",
    "- **Similarity**: `cosine` (measures angle between vectors, not magnitude)\n",
    "- **Type**: `knnVector` (k-nearest neighbors for fast similarity search)\n",
    "\n",
    "**How it works:**\n",
    "1. ğŸ” You provide a query (e.g., \"cozy apartment near restaurants\")\n",
    "2. ğŸ”„ Query gets converted to a 1536-dimension vector\n",
    "3. ğŸ“ MongoDB compares your query vector with all stored vectors using cosine similarity\n",
    "4. ğŸ“Š Returns the most similar listings ranked by similarity score\n",
    "\n",
    "**Why cosine similarity?**\n",
    "- Focuses on direction/content rather than magnitude\n",
    "- Perfect for text embeddings where meaning matters more than absolute values\n",
    "- Range: -1 (opposite) to 1 (identical)\n",
    "\n",
    "**Index benefits:**\n",
    "- âš¡ **Speed**: Fast searches through millions of vectors\n",
    "- ğŸ¯ **Accuracy**: Finds semantically similar content\n",
    "- ğŸ“ˆ **Scalability**: Efficient even with large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Creating vector search index with detailed configuration...\n",
      "ğŸ“‹ Index Configuration:\n",
      "  Field: text_embeddings\n",
      "  Name: vector_index_text\n",
      "  Dimensions: 1536 (OpenAI text-embedding-3-small)\n",
      "  Similarity: cosine (best for text embeddings)\n",
      "  Type: knnVector (k-nearest neighbors)\n",
      "\n",
      "ğŸ” Checking existing indexes...\n",
      "  Found index: _id_\n",
      "\n",
      "ğŸ“ Creating new vector search index: vector_index_text\n",
      "âœ… Vector search index created successfully!\n",
      "ğŸ“„ Index ID: vector_index_text\n",
      "â³ Index is initializing... (may take a few minutes)\n",
      "ğŸ’¡ You can proceed - the index will be ready shortly\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Create Vector Search Index (with detailed explanations)\n",
    "print(\"ğŸ” Creating vector search index with detailed configuration...\")\n",
    "\n",
    "if MONGO_URI:\n",
    "    # Define index configuration (following Lesson_1.md approach)\n",
    "    text_embedding_field_name = \"text_embeddings\"  # Field containing our embeddings\n",
    "    vector_search_index_name = \"vector_index_text\"  # Index identifier\n",
    "    \n",
    "    print(f\"ğŸ“‹ Index Configuration:\")\n",
    "    print(f\"  Field: {text_embedding_field_name}\")\n",
    "    print(f\"  Name: {vector_search_index_name}\")\n",
    "    print(f\"  Dimensions: 1536 (OpenAI text-embedding-3-small)\")\n",
    "    print(f\"  Similarity: cosine (best for text embeddings)\")\n",
    "    print(f\"  Type: knnVector (k-nearest neighbors)\")\n",
    "    \n",
    "    vector_search_index_model = SearchIndexModel(\n",
    "        definition={\n",
    "            \"mappings\": {  # Describes how fields are indexed and stored\n",
    "                \"dynamic\": True,  # Automatically index new fields that appear\n",
    "                \"fields\": {  # Properties of the fields that will be indexed\n",
    "                    text_embedding_field_name: {\n",
    "                        \"dimensions\": 1536,  # Size of the vector (must match embeddings)\n",
    "                        \"similarity\": \"cosine\",  # Algorithm for computing similarity\n",
    "                        \"type\": \"knnVector\",  # Vector search type\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        name=vector_search_index_name,  # Identifier for the vector search index\n",
    "    )\n",
    "    \n",
    "    # Check if index already exists\n",
    "    index_exists = False\n",
    "    print(\"\\nğŸ” Checking existing indexes...\")\n",
    "    \n",
    "    for index in collection.list_indexes():\n",
    "        print(f\"  Found index: {index.get('name', 'unnamed')}\")\n",
    "        if index.get('name') == vector_search_index_name:\n",
    "            index_exists = True\n",
    "    \n",
    "    if not index_exists:\n",
    "        print(f\"\\nğŸ“ Creating new vector search index: {vector_search_index_name}\")\n",
    "        try:\n",
    "            result = collection.create_search_index(model=vector_search_index_model)\n",
    "            print(f\"âœ… Vector search index created successfully!\")\n",
    "            print(f\"ğŸ“„ Index ID: {result}\")\n",
    "            print(\"â³ Index is initializing... (may take a few minutes)\")\n",
    "            print(\"ğŸ’¡ You can proceed - the index will be ready shortly\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating index: {e}\")\n",
    "            if \"Duplicate Index\" in str(e):\n",
    "                print(\"ğŸ’¡ Index might already exist with a different name\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… Vector search index '{vector_search_index_name}' already exists!\")\n",
    "        print(\"ğŸ¯ Ready for vector searches!\")\n",
    "else:\n",
    "    print(\"âŒ Cannot create index - missing MONGO_URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've successfully:\n",
    "1. âœ… Loaded Airbnb dataset with embeddings\n",
    "2. âœ… Analyzed data structure (main vs nested fields)\n",
    "3. âœ… Created Pydantic models for validation\n",
    "4. âœ… Processed and validated all records\n",
    "5. âœ… Connected to MongoDB Atlas\n",
    "6. âœ… Inserted data into MongoDB\n",
    "7. âœ… Created vector search index\n",
    "\n",
    "**Next steps:** Implement vector search functionality and test queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing embedding generation...\n",
      "âœ… Created embedding: 1536 dimensions\n",
      "ğŸ“Š Query: 'cozy apartment near beach' â†’ 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Create embedding function for queries\n",
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for the given text using OpenAI's API.\n",
    "    \n",
    "    This converts any text into a 1536-dimension vector that can be\n",
    "    compared with our stored listing embeddings.\n",
    "    \"\"\"\n",
    "    # Check for valid input\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Call OpenAI API to get the embedding\n",
    "        embedding = openai.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-3-small\", \n",
    "            dimensions=1536\n",
    "        ).data[0].embedding\n",
    "        \n",
    "        print(f\"âœ… Created embedding: {len(embedding)} dimensions\")\n",
    "        return embedding\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in get_embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test it\n",
    "print(\"ğŸ§ª Testing embedding generation...\")\n",
    "test_query = \"cozy apartment near beach\"\n",
    "test_embedding = get_embedding(test_query)\n",
    "print(f\"ğŸ“Š Query: '{test_query}' â†’ {len(test_embedding)} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector search function ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Vector Search Function\n",
    "def vector_search(user_query, db, collection, vector_index=\"vector_index_text\"):\n",
    "    \"\"\"\n",
    "    Perform a vector search in MongoDB based on user query.\n",
    "    \n",
    "    How it works:\n",
    "    1. Convert user's text query into an embedding (1536-dim vector)\n",
    "    2. Use MongoDB's $vectorSearch to find similar listings\n",
    "    3. Return top 20 most similar results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ” Searching for: '{user_query}'\")\n",
    "    \n",
    "    # Step 1: Generate embedding for the user query\n",
    "    query_embedding = get_embedding(user_query)\n",
    "    \n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    \n",
    "    # Step 2: Define the vector search stage\n",
    "    vector_search_stage = {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": vector_index,  # Which index to use\n",
    "            \"queryVector\": query_embedding,  # Our query as a vector\n",
    "            \"path\": text_embedding_field_name,  # Field to search in documents\n",
    "            \"numCandidates\": 150,  # Number of candidates to consider\n",
    "            \"limit\": 20  # Return top 20 matches\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Step 3: Build aggregation pipeline\n",
    "    pipeline = [vector_search_stage]\n",
    "    \n",
    "    # Step 4: Execute the search\n",
    "    print(\"ğŸ” Running vector search...\")\n",
    "    results = collection.aggregate(pipeline)\n",
    "    \n",
    "    # Step 5: Get execution stats (how long it took)\n",
    "    explain_query_execution = db.command(\n",
    "        'explain', {\n",
    "            'aggregate': collection.name,\n",
    "            'pipeline': pipeline,\n",
    "            'cursor': {}\n",
    "        },\n",
    "        verbosity='executionStats'\n",
    "    )\n",
    "    \n",
    "    vector_search_explain = explain_query_execution['stages'][0]['$vectorSearch']\n",
    "    millis_elapsed = vector_search_explain['explain']['collectors']['allCollectorStats']['millisElapsed']\n",
    "    \n",
    "    print(f\"âš¡ Search completed in {millis_elapsed} milliseconds\")\n",
    "    \n",
    "    return list(results)\n",
    "\n",
    "print(\"âœ… Vector search function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing vector search with a simple query...\n",
      "\n",
      "ğŸ” Searching for: 'beach house with pool'\n",
      "âœ… Created embedding: 1536 dimensions\n",
      "ğŸ” Running vector search...\n",
      "âš¡ Search completed in 0.158292 milliseconds\n",
      "\n",
      "ğŸ“Š Found 20 results\n",
      "\n",
      "ğŸ† Top 3 matches:\n",
      "\n",
      "1. Surry Hills Studio - Your Perfect Base in Sydney\n",
      "   ğŸ’° Price: $181\n",
      "   ğŸ  Type: Apartment\n",
      "   ğŸ“ Location: Sydney, Australia\n",
      "   ğŸ“ Summary: This spacious, light filled studio has everything you need to enjoy Sydney and is the perfect base f...\n",
      "\n",
      "2. Ocean View Waikiki Marina w/prkg\n",
      "   ğŸ’° Price: $115\n",
      "   ğŸ  Type: Condominium\n",
      "   ğŸ“ Location: Oahu, United States\n",
      "   ğŸ“ Summary: A short distance from Honolulu's billion dollar mall, and the same distance to Waikiki. Parking incl...\n",
      "\n",
      "3. Copacabana Apartment Posto 6\n",
      "   ğŸ’° Price: $119\n",
      "   ğŸ  Type: Apartment\n",
      "   ğŸ“ Location: Rio De Janeiro, Brazil\n",
      "   ğŸ“ Summary: The Apartment has a living room, toilet, bedroom (suite) and American kitchen. Well located, on the ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Test Vector Search (Simple)\n",
    "print(\"ğŸ§ª Testing vector search with a simple query...\\n\")\n",
    "\n",
    "# Simple test query\n",
    "test_query = \"beach house with pool\"\n",
    "\n",
    "# Run the search\n",
    "search_results = vector_search(test_query, db, collection)\n",
    "\n",
    "print(f\"\\nğŸ“Š Found {len(search_results)} results\\n\")\n",
    "\n",
    "# Show top 3 results\n",
    "print(\"ğŸ† Top 3 matches:\")\n",
    "for i, result in enumerate(search_results[:3], 1):\n",
    "    print(f\"\\n{i}. {result['name']}\")\n",
    "    print(f\"   ğŸ’° Price: ${result['price']}\")\n",
    "    print(f\"   ğŸ  Type: {result['property_type']}\")\n",
    "    print(f\"   ğŸ“ Location: {result['address']['market']}, {result['address']['country']}\")\n",
    "    print(f\"   ğŸ“ Summary: {result['summary'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SearchResultItem model ready for displaying results\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Create SearchResultItem model (for clean display)\n",
    "class SearchResultItem(BaseModel):\n",
    "    name: str\n",
    "    accommodates: Optional[int] = None\n",
    "    address: Address\n",
    "    summary: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    neighborhood_overview: Optional[str] = None\n",
    "    price: int\n",
    "    property_type: str\n",
    "\n",
    "print(\"âœ… SearchResultItem model ready for displaying results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Complete query handler ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Handle User Query with GPT Recommendations\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def handle_user_query(query, db, collection):\n",
    "    \"\"\"\n",
    "    Complete search pipeline:\n",
    "    1. Run vector search to find similar listings\n",
    "    2. Convert results to clean format\n",
    "    3. Use GPT to generate natural language recommendations\n",
    "    4. Display results nicely\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Run vector search\n",
    "    get_knowledge = vector_search(query, db, collection)\n",
    "    \n",
    "    # Check if there are any results\n",
    "    if not get_knowledge:\n",
    "        return \"No results found.\", \"No source information available.\"\n",
    "    \n",
    "    # Step 2: Convert search results into SearchResultItem models\n",
    "    search_results_models = [\n",
    "        SearchResultItem(**result)\n",
    "        for result in get_knowledge\n",
    "    ]\n",
    "    \n",
    "    # Convert to DataFrame for GPT and display\n",
    "    search_results_df = pd.DataFrame([item.dict() for item in search_results_models])\n",
    "    \n",
    "    # Step 3: Generate system response using GPT\n",
    "    print(\"\\nğŸ¤– Generating recommendation with GPT...\\n\")\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an Airbnb listing recommendation system.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Answer this user query: {query} with the following context:\\n{search_results_df}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    system_response = completion.choices[0].message.content\n",
    "    \n",
    "    # Step 4: Display results\n",
    "    print(f\"â”\" * 80)\n",
    "    print(f\"â“ USER QUESTION:\")\n",
    "    print(f\"{query}\\n\")\n",
    "    print(f\"â”\" * 80)\n",
    "    print(f\"ğŸ¤– RECOMMENDATION:\")\n",
    "    print(f\"{system_response}\\n\")\n",
    "    print(f\"â”\" * 80)\n",
    "    print(f\"ğŸ“‹ SOURCE DATA:\")\n",
    "    display(HTML(search_results_df.to_html()))\n",
    "    \n",
    "    return system_response\n",
    "\n",
    "print(\"âœ… Complete query handler ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Test Full System with Natural Language Query\n",
    "query = \"\"\"\n",
    "I want to stay in a place that's warm and friendly, \n",
    "and not too far from restaurants. Can you recommend a place? \n",
    "Include a reason as to why you've chosen your selection.\n",
    "\"\"\"\n",
    "\n",
    "handle_user_query(query, db, collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
