{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Vector Search Tutorial\n",
    "## Step-by-step learning with Airbnb dataset\n",
    "\n",
    "Run cells in order: 1 → 2 → 3 → ... → 17\n",
    "\n",
    "**What we'll build:**\n",
    "1. Load Airbnb dataset with embeddings (Cells 1-4)\n",
    "2. Create Pydantic models for data validation (Cells 5-8)\n",
    "3. Connect to MongoDB Atlas and insert data (Cells 9-10)\n",
    "4. Create vector search index (Cells 11-12)\n",
    "5. Implement vector search (Cells 12-14)\n",
    "6. Build GPT-powered recommendation system (Cells 15-17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ All imports loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API Key: Found\n",
      "✅ MongoDB URI: Found\n",
      "✅ HuggingFace Token: Found\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load API keys\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\") \n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "print(\"✅ OpenAI API Key:\", \"Found\" if OPENAI_API_KEY else \"❌ Missing\")\n",
    "print(\"✅ MongoDB URI:\", \"Found\" if MONGO_URI else \"❌ Missing\")  \n",
    "print(\"✅ HuggingFace Token:\", \"Found\" if HF_TOKEN else \"❌ Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading Airbnb dataset...\n",
      "✅ Loaded 20 records\n",
      "📊 Shape: (20, 43)\n",
      "🔗 Embeddings: 1536 dimensions\n",
      "\n",
      "🏠 Sample: Ribeira Charming Duplex - $80 - 8 guests\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load dataset\n",
    "print(\"🔄 Loading Airbnb dataset...\")\n",
    "\n",
    "dataset = load_dataset(\"MongoDB/airbnb_embeddings\", streaming=True, split=\"train\")\n",
    "dataset = dataset.take(20)\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(f\"✅ Loaded {len(dataset_df)} records\")\n",
    "print(f\"📊 Shape: {dataset_df.shape}\")\n",
    "print(f\"🔗 Embeddings: {len(dataset_df.iloc[0]['text_embeddings'])} dimensions\")\n",
    "\n",
    "# Show sample\n",
    "sample = dataset_df.iloc[0]\n",
    "print(f\"\\n🏠 Sample: {sample['name']} - ${sample['price']} - {sample['accommodates']} guests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 How I identify main vs nested structures:\n",
      "\n",
      "📊 Field types:\n",
      "  _id             | int64    | 10006546...\n",
      "  name            | str      | Ribeira Charming Duplex...\n",
      "  price           | int64    | 80...\n",
      "  host            | dict     | dict with 16 keys: ['host_id', 'host_url', 'host_name']...\n",
      "  address         | dict     | dict with 7 keys: ['street', 'suburb', 'government_area']...\n",
      "  text_embeddings | list     | list with 1536 items\n",
      "\n",
      "💡 Pattern:\n",
      "  - Simple types (str, int) = main fields\n",
      "  - dict type = needs separate Pydantic model\n",
      "  - list of floats = embeddings for vector search\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Analyze data structure\n",
    "print(\"🔍 How I identify main vs nested structures:\\n\")\n",
    "\n",
    "sample = dataset_df.iloc[0]\n",
    "\n",
    "print(\"📊 Field types:\")\n",
    "for field_name in ['_id', 'name', 'price', 'host', 'address', 'text_embeddings']:\n",
    "    if field_name in sample:\n",
    "        value = sample[field_name]\n",
    "        field_type = type(value).__name__\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            preview = f\"dict with {len(value)} keys: {list(value.keys())[:3]}...\"\n",
    "        elif isinstance(value, list):\n",
    "            preview = f\"list with {len(value)} items\"\n",
    "        else:\n",
    "            preview = f\"{str(value)[:30]}...\"\n",
    "            \n",
    "        print(f\"  {field_name:15} | {field_type:8} | {preview}\")\n",
    "\n",
    "print(\"\\n💡 Pattern:\")\n",
    "print(\"  - Simple types (str, int) = main fields\")\n",
    "print(\"  - dict type = needs separate Pydantic model\")\n",
    "print(\"  - list of floats = embeddings for vector search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ Creating Pydantic models...\n",
      "✅ Models created: Host, Location, Address, Listing\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Pydantic models\n",
    "print(\"🏗️ Creating Pydantic models...\")\n",
    "\n",
    "class Host(BaseModel):\n",
    "    host_id: str\n",
    "    host_name: str\n",
    "    host_is_superhost: bool\n",
    "    host_has_profile_pic: bool\n",
    "    host_identity_verified: bool\n",
    "    host_url: Optional[str] = None\n",
    "    host_location: Optional[str] = None\n",
    "    host_about: Optional[str] = None\n",
    "    host_response_time: Optional[str] = None\n",
    "    host_thumbnail_url: Optional[str] = None\n",
    "    host_picture_url: Optional[str] = None\n",
    "    host_response_rate: Optional[int] = None\n",
    "\n",
    "class Location(BaseModel):\n",
    "    type: str\n",
    "    coordinates: List[float]\n",
    "    is_location_exact: bool\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    government_area: str\n",
    "    market: str\n",
    "    country: str\n",
    "    country_code: str\n",
    "    location: Location\n",
    "\n",
    "class Listing(BaseModel):\n",
    "    _id: int\n",
    "    name: str\n",
    "    summary: str\n",
    "    property_type: str\n",
    "    room_type: str\n",
    "    price: int\n",
    "    accommodates: int\n",
    "    host: Host\n",
    "    address: Address\n",
    "    text_embeddings: List[float]\n",
    "    \n",
    "    # Optional fields\n",
    "    listing_url: Optional[str] = None\n",
    "    space: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    neighborhood_overview: Optional[str] = None\n",
    "    notes: Optional[str] = None\n",
    "    transit: Optional[str] = None\n",
    "    access: Optional[str] = None\n",
    "    interaction: Optional[str] = None\n",
    "    house_rules: Optional[str] = None\n",
    "    bed_type: Optional[str] = None\n",
    "    minimum_nights: Optional[int] = None\n",
    "    maximum_nights: Optional[int] = None\n",
    "    cancellation_policy: Optional[str] = None\n",
    "    bedrooms: Optional[float] = 0\n",
    "    beds: Optional[float] = 0\n",
    "    bathrooms: Optional[float] = 0\n",
    "    number_of_reviews: Optional[int] = 0\n",
    "    amenities: Optional[List[str]] = []\n",
    "    security_deposit: Optional[float] = None\n",
    "    cleaning_fee: Optional[float] = None\n",
    "    extra_people: Optional[int] = 0\n",
    "    guests_included: Optional[int] = 1\n",
    "\n",
    "print(\"✅ Models created: Host, Location, Address, Listing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data cleaner function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Simple data cleaner (handles the NaN/array issue)\n",
    "def clean_record(record):\n",
    "    \"\"\"Clean record - handle NaN values safely\"\"\"\n",
    "    cleaned = {}\n",
    "    for key, value in record.items():\n",
    "        if value is None:\n",
    "            cleaned[key] = None\n",
    "        elif isinstance(value, (dict, list)):\n",
    "            cleaned[key] = value  # Keep complex types as-is\n",
    "        else:\n",
    "            # Only check scalar values for NaN\n",
    "            try:\n",
    "                if pd.isna(value):\n",
    "                    cleaned[key] = None\n",
    "                else:\n",
    "                    cleaned[key] = value\n",
    "            except (ValueError, TypeError):\n",
    "                cleaned[key] = value  # Keep original if check fails\n",
    "    return cleaned\n",
    "\n",
    "print(\"✅ Data cleaner function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing Pydantic with first record...\n",
      "🎉 SUCCESS! Pydantic validation passed!\n",
      "📋 Name: Ribeira Charming Duplex\n",
      "💰 Price: $80 (converted to int)\n",
      "👥 Accommodates: 8\n",
      "🏠 Type: House\n",
      "🌍 Location: Porto, Portugal\n",
      "⭐ Superhost: False\n",
      "🔗 Embeddings: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test with one record\n",
    "print(\"🧪 Testing Pydantic with first record...\")\n",
    "\n",
    "sample_record = dataset_df.iloc[0].to_dict()\n",
    "cleaned_record = clean_record(sample_record)\n",
    "\n",
    "try:\n",
    "    listing = Listing(**cleaned_record)\n",
    "    \n",
    "    print(\"🎉 SUCCESS! Pydantic validation passed!\")\n",
    "    print(f\"📋 Name: {listing.name}\")\n",
    "    print(f\"💰 Price: ${listing.price} (converted to int)\")\n",
    "    print(f\"👥 Accommodates: {listing.accommodates}\")\n",
    "    print(f\"🏠 Type: {listing.property_type}\")\n",
    "    print(f\"🌍 Location: {listing.address.market}, {listing.address.country}\")\n",
    "    print(f\"⭐ Superhost: {listing.host.host_is_superhost}\")\n",
    "    print(f\"🔗 Embeddings: {len(listing.text_embeddings)} dimensions\")\n",
    "    \n",
    "except ValidationError as e:\n",
    "    print(\"❌ Validation failed:\")\n",
    "    for error in e.errors():\n",
    "        field = ' -> '.join(str(x) for x in error['loc'])\n",
    "        print(f\"  {field}: {error['msg']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❓ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing all 20 records...\n",
      "✅ 1: Ribeira Charming Duplex... ($80)\n",
      "✅ 2: Private Room in Bushwick... ($40)\n",
      "✅ 3: Ocean View Waikiki Marina w/pr... ($115)\n",
      "\n",
      "📊 Results:\n",
      "  ✅ Validated: 20 records\n",
      "  ❌ Failed: 0 records\n",
      "\n",
      "🎯 Ready for MongoDB! Each record has:\n",
      "  - Validated data types\n",
      "  - 1536-dimension embeddings\n",
      "  - Structured host & address info\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Process all records\n",
    "print(\"🔄 Processing all 20 records...\")\n",
    "\n",
    "validated_listings = []\n",
    "errors = []\n",
    "\n",
    "for i, record in enumerate(dataset_df.to_dict('records')):\n",
    "    try:\n",
    "        cleaned_record = clean_record(record)\n",
    "        listing = Listing(**cleaned_record)\n",
    "        validated_listings.append(listing.dict())\n",
    "        \n",
    "        if i < 3:\n",
    "            print(f\"✅ {i+1}: {listing.name[:30]}... (${listing.price})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append((i, str(e)))\n",
    "        print(f\"❌ {i+1}: Failed\")\n",
    "\n",
    "print(f\"\\n📊 Results:\")\n",
    "print(f\"  ✅ Validated: {len(validated_listings)} records\")\n",
    "print(f\"  ❌ Failed: {len(errors)} records\")\n",
    "\n",
    "if validated_listings:\n",
    "    print(\"\\n🎯 Ready for MongoDB! Each record has:\")\n",
    "    print(\"  - Validated data types\")\n",
    "    print(\"  - 1536-dimension embeddings\")\n",
    "    print(\"  - Structured host & address info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 Setting up MongoDB Atlas connection...\n",
      "✅ Connection to MongoDB Atlas successful!\n",
      "📋 Database: airbnb_dataset\n",
      "📋 Collection: listings_reviews\n",
      "🎯 Ready to insert 20 records!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: MongoDB Atlas Connection\n",
    "print(\"🔌 Setting up MongoDB Atlas connection...\")\n",
    "\n",
    "# Database and collection names\n",
    "database_name = \"airbnb_dataset\"\n",
    "collection_name = \"listings_reviews\"\n",
    "\n",
    "def get_mongo_client(mongo_uri):\n",
    "    \"\"\"Establish connection to MongoDB Atlas\"\"\"\n",
    "    client = MongoClient(mongo_uri, appname=\"devrel.deeplearningai.lesson1.python\")\n",
    "    print(\"✅ Connection to MongoDB Atlas successful!\")\n",
    "    return client\n",
    "\n",
    "if not MONGO_URI:\n",
    "    print(\"❌ MONGO_URI not set in environment variables\")\n",
    "else:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = get_mongo_client(MONGO_URI)\n",
    "    \n",
    "    # Get database and collection\n",
    "    db = mongo_client.get_database(database_name)\n",
    "    collection = db.get_collection(collection_name)\n",
    "    \n",
    "    print(f\"📋 Database: {database_name}\")\n",
    "    print(f\"📋 Collection: {collection_name}\")\n",
    "    print(f\"🎯 Ready to insert {len(validated_listings)} records!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Inserting validated data into MongoDB...\n",
      "🗑️ Clearing existing data...\n",
      "Deleted 20 existing records\n",
      "📥 Inserting 20 records...\n",
      "✅ Successfully inserted 20 records!\n",
      "🎯 Collection now has 20 documents\n",
      "\n",
      "📋 Sample document structure:\n",
      "  - ID: 68de8b5b53eb7044f9e73371\n",
      "  - Name: Ribeira Charming Duplex\n",
      "  - Price: $80\n",
      "  - Embeddings: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Insert Data into MongoDB\n",
    "print(\"💾 Inserting validated data into MongoDB...\")\n",
    "\n",
    "if MONGO_URI and validated_listings:\n",
    "    # Clear any existing data (optional - be careful!)\n",
    "    print(\"🗑️ Clearing existing data...\")\n",
    "    result = collection.delete_many({})\n",
    "    print(f\"Deleted {result.deleted_count} existing records\")\n",
    "    \n",
    "    # Insert our validated listings\n",
    "    print(f\"📥 Inserting {len(validated_listings)} records...\")\n",
    "    insert_result = collection.insert_many(validated_listings)\n",
    "    \n",
    "    print(f\"✅ Successfully inserted {len(insert_result.inserted_ids)} records!\")\n",
    "    print(f\"🎯 Collection now has {collection.count_documents({})} documents\")\n",
    "    \n",
    "    # Show a sample document\n",
    "    sample_doc = collection.find_one()\n",
    "    if sample_doc:\n",
    "        print(f\"\\n📋 Sample document structure:\")\n",
    "        print(f\"  - ID: {sample_doc['_id']}\")\n",
    "        print(f\"  - Name: {sample_doc['name']}\")\n",
    "        print(f\"  - Price: ${sample_doc['price']}\")\n",
    "        print(f\"  - Embeddings: {len(sample_doc['text_embeddings'])} dimensions\")\n",
    "else:\n",
    "    print(\"❌ Cannot insert - missing MONGO_URI or no validated listings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Vector Search Index\n",
    "\n",
    "**What is a Vector Search Index?**\n",
    "A vector search index is a special data structure that enables fast similarity searches through high-dimensional vectors (our embeddings).\n",
    "\n",
    "**Key Components:**\n",
    "- **Field**: `text_embeddings` (our 1536-dimension vectors)\n",
    "- **Dimensions**: 1536 (matches OpenAI's text-embedding-3-small model)\n",
    "- **Similarity**: `cosine` (measures angle between vectors, not magnitude)\n",
    "- **Type**: `knnVector` (k-nearest neighbors for fast similarity search)\n",
    "\n",
    "**How it works:**\n",
    "1. 🔍 You provide a query (e.g., \"cozy apartment near restaurants\")\n",
    "2. 🔄 Query gets converted to a 1536-dimension vector\n",
    "3. 📐 MongoDB compares your query vector with all stored vectors using cosine similarity\n",
    "4. 📊 Returns the most similar listings ranked by similarity score\n",
    "\n",
    "**Why cosine similarity?**\n",
    "- Focuses on direction/content rather than magnitude\n",
    "- Perfect for text embeddings where meaning matters more than absolute values\n",
    "- Range: -1 (opposite) to 1 (identical)\n",
    "\n",
    "**Index benefits:**\n",
    "- ⚡ **Speed**: Fast searches through millions of vectors\n",
    "- 🎯 **Accuracy**: Finds semantically similar content\n",
    "- 📈 **Scalability**: Efficient even with large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Creating vector search index with detailed configuration...\n",
      "📋 Index Configuration:\n",
      "  Field: text_embeddings\n",
      "  Name: vector_index_text\n",
      "  Dimensions: 1536 (OpenAI text-embedding-3-small)\n",
      "  Similarity: cosine (best for text embeddings)\n",
      "  Type: knnVector (k-nearest neighbors)\n",
      "\n",
      "🔍 Checking existing indexes...\n",
      "  Found index: _id_\n",
      "\n",
      "📝 Creating new vector search index: vector_index_text\n",
      "✅ Vector search index created successfully!\n",
      "📄 Index ID: vector_index_text\n",
      "⏳ Index is initializing... (may take a few minutes)\n",
      "💡 You can proceed - the index will be ready shortly\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Create Vector Search Index (with detailed explanations)\n",
    "print(\"🔍 Creating vector search index with detailed configuration...\")\n",
    "\n",
    "if MONGO_URI:\n",
    "    # Define index configuration (following Lesson_1.md approach)\n",
    "    text_embedding_field_name = \"text_embeddings\"  # Field containing our embeddings\n",
    "    vector_search_index_name = \"vector_index_text\"  # Index identifier\n",
    "    \n",
    "    print(f\"📋 Index Configuration:\")\n",
    "    print(f\"  Field: {text_embedding_field_name}\")\n",
    "    print(f\"  Name: {vector_search_index_name}\")\n",
    "    print(f\"  Dimensions: 1536 (OpenAI text-embedding-3-small)\")\n",
    "    print(f\"  Similarity: cosine (best for text embeddings)\")\n",
    "    print(f\"  Type: knnVector (k-nearest neighbors)\")\n",
    "    \n",
    "    vector_search_index_model = SearchIndexModel(\n",
    "        definition={\n",
    "            \"mappings\": {  # Describes how fields are indexed and stored\n",
    "                \"dynamic\": True,  # Automatically index new fields that appear\n",
    "                \"fields\": {  # Properties of the fields that will be indexed\n",
    "                    text_embedding_field_name: {\n",
    "                        \"dimensions\": 1536,  # Size of the vector (must match embeddings)\n",
    "                        \"similarity\": \"cosine\",  # Algorithm for computing similarity\n",
    "                        \"type\": \"knnVector\",  # Vector search type\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        name=vector_search_index_name,  # Identifier for the vector search index\n",
    "    )\n",
    "    \n",
    "    # Check if index already exists\n",
    "    index_exists = False\n",
    "    print(\"\\n🔍 Checking existing indexes...\")\n",
    "    \n",
    "    for index in collection.list_indexes():\n",
    "        print(f\"  Found index: {index.get('name', 'unnamed')}\")\n",
    "        if index.get('name') == vector_search_index_name:\n",
    "            index_exists = True\n",
    "    \n",
    "    if not index_exists:\n",
    "        print(f\"\\n📝 Creating new vector search index: {vector_search_index_name}\")\n",
    "        try:\n",
    "            result = collection.create_search_index(model=vector_search_index_model)\n",
    "            print(f\"✅ Vector search index created successfully!\")\n",
    "            print(f\"📄 Index ID: {result}\")\n",
    "            print(\"⏳ Index is initializing... (may take a few minutes)\")\n",
    "            print(\"💡 You can proceed - the index will be ready shortly\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating index: {e}\")\n",
    "            if \"Duplicate Index\" in str(e):\n",
    "                print(\"💡 Index might already exist with a different name\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Vector search index '{vector_search_index_name}' already exists!\")\n",
    "        print(\"🎯 Ready for vector searches!\")\n",
    "else:\n",
    "    print(\"❌ Cannot create index - missing MONGO_URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've successfully:\n",
    "1. ✅ Loaded Airbnb dataset with embeddings\n",
    "2. ✅ Analyzed data structure (main vs nested fields)\n",
    "3. ✅ Created Pydantic models for validation\n",
    "4. ✅ Processed and validated all records\n",
    "5. ✅ Connected to MongoDB Atlas\n",
    "6. ✅ Inserted data into MongoDB\n",
    "7. ✅ Created vector search index\n",
    "\n",
    "**Next steps:** Implement vector search functionality and test queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing embedding generation...\n",
      "✅ Created embedding: 1536 dimensions\n",
      "📊 Query: 'cozy apartment near beach' → 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Create embedding function for queries\n",
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for the given text using OpenAI's API.\n",
    "    \n",
    "    This converts any text into a 1536-dimension vector that can be\n",
    "    compared with our stored listing embeddings.\n",
    "    \"\"\"\n",
    "    # Check for valid input\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Call OpenAI API to get the embedding\n",
    "        embedding = openai.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-3-small\", \n",
    "            dimensions=1536\n",
    "        ).data[0].embedding\n",
    "        \n",
    "        print(f\"✅ Created embedding: {len(embedding)} dimensions\")\n",
    "        return embedding\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in get_embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test it\n",
    "print(\"🧪 Testing embedding generation...\")\n",
    "test_query = \"cozy apartment near beach\"\n",
    "test_embedding = get_embedding(test_query)\n",
    "print(f\"📊 Query: '{test_query}' → {len(test_embedding)} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector search function ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Vector Search Function\n",
    "def vector_search(user_query, db, collection, vector_index=\"vector_index_text\"):\n",
    "    \"\"\"\n",
    "    Perform a vector search in MongoDB based on user query.\n",
    "    \n",
    "    How it works:\n",
    "    1. Convert user's text query into an embedding (1536-dim vector)\n",
    "    2. Use MongoDB's $vectorSearch to find similar listings\n",
    "    3. Return top 20 most similar results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"🔍 Searching for: '{user_query}'\")\n",
    "    \n",
    "    # Step 1: Generate embedding for the user query\n",
    "    query_embedding = get_embedding(user_query)\n",
    "    \n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    \n",
    "    # Step 2: Define the vector search stage\n",
    "    vector_search_stage = {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": vector_index,  # Which index to use\n",
    "            \"queryVector\": query_embedding,  # Our query as a vector\n",
    "            \"path\": text_embedding_field_name,  # Field to search in documents\n",
    "            \"numCandidates\": 150,  # Number of candidates to consider\n",
    "            \"limit\": 20  # Return top 20 matches\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Step 3: Build aggregation pipeline\n",
    "    pipeline = [vector_search_stage]\n",
    "    \n",
    "    # Step 4: Execute the search\n",
    "    print(\"🔎 Running vector search...\")\n",
    "    results = collection.aggregate(pipeline)\n",
    "    \n",
    "    # Step 5: Get execution stats (how long it took)\n",
    "    explain_query_execution = db.command(\n",
    "        'explain', {\n",
    "            'aggregate': collection.name,\n",
    "            'pipeline': pipeline,\n",
    "            'cursor': {}\n",
    "        },\n",
    "        verbosity='executionStats'\n",
    "    )\n",
    "    \n",
    "    vector_search_explain = explain_query_execution['stages'][0]['$vectorSearch']\n",
    "    millis_elapsed = vector_search_explain['explain']['collectors']['allCollectorStats']['millisElapsed']\n",
    "    \n",
    "    print(f\"⚡ Search completed in {millis_elapsed} milliseconds\")\n",
    "    \n",
    "    return list(results)\n",
    "\n",
    "print(\"✅ Vector search function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing vector search with a simple query...\n",
      "\n",
      "🔍 Searching for: 'beach house with pool'\n",
      "✅ Created embedding: 1536 dimensions\n",
      "🔎 Running vector search...\n",
      "⚡ Search completed in 0.158292 milliseconds\n",
      "\n",
      "📊 Found 20 results\n",
      "\n",
      "🏆 Top 3 matches:\n",
      "\n",
      "1. Surry Hills Studio - Your Perfect Base in Sydney\n",
      "   💰 Price: $181\n",
      "   🏠 Type: Apartment\n",
      "   📍 Location: Sydney, Australia\n",
      "   📝 Summary: This spacious, light filled studio has everything you need to enjoy Sydney and is the perfect base f...\n",
      "\n",
      "2. Ocean View Waikiki Marina w/prkg\n",
      "   💰 Price: $115\n",
      "   🏠 Type: Condominium\n",
      "   📍 Location: Oahu, United States\n",
      "   📝 Summary: A short distance from Honolulu's billion dollar mall, and the same distance to Waikiki. Parking incl...\n",
      "\n",
      "3. Copacabana Apartment Posto 6\n",
      "   💰 Price: $119\n",
      "   🏠 Type: Apartment\n",
      "   📍 Location: Rio De Janeiro, Brazil\n",
      "   📝 Summary: The Apartment has a living room, toilet, bedroom (suite) and American kitchen. Well located, on the ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Test Vector Search (Simple)\n",
    "print(\"🧪 Testing vector search with a simple query...\\n\")\n",
    "\n",
    "# Simple test query\n",
    "test_query = \"beach house with pool\"\n",
    "\n",
    "# Run the search\n",
    "search_results = vector_search(test_query, db, collection)\n",
    "\n",
    "print(f\"\\n📊 Found {len(search_results)} results\\n\")\n",
    "\n",
    "# Show top 3 results\n",
    "print(\"🏆 Top 3 matches:\")\n",
    "for i, result in enumerate(search_results[:3], 1):\n",
    "    print(f\"\\n{i}. {result['name']}\")\n",
    "    print(f\"   💰 Price: ${result['price']}\")\n",
    "    print(f\"   🏠 Type: {result['property_type']}\")\n",
    "    print(f\"   📍 Location: {result['address']['market']}, {result['address']['country']}\")\n",
    "    print(f\"   📝 Summary: {result['summary'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SearchResultItem model ready for displaying results\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Create SearchResultItem model (for clean display)\n",
    "class SearchResultItem(BaseModel):\n",
    "    name: str\n",
    "    accommodates: Optional[int] = None\n",
    "    address: Address\n",
    "    summary: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    neighborhood_overview: Optional[str] = None\n",
    "    price: int\n",
    "    property_type: str\n",
    "\n",
    "print(\"✅ SearchResultItem model ready for displaying results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Complete query handler ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Handle User Query with GPT Recommendations\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def handle_user_query(query, db, collection):\n",
    "    \"\"\"\n",
    "    Complete search pipeline:\n",
    "    1. Run vector search to find similar listings\n",
    "    2. Convert results to clean format\n",
    "    3. Use GPT to generate natural language recommendations\n",
    "    4. Display results nicely\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Run vector search\n",
    "    get_knowledge = vector_search(query, db, collection)\n",
    "    \n",
    "    # Check if there are any results\n",
    "    if not get_knowledge:\n",
    "        return \"No results found.\", \"No source information available.\"\n",
    "    \n",
    "    # Step 2: Convert search results into SearchResultItem models\n",
    "    search_results_models = [\n",
    "        SearchResultItem(**result)\n",
    "        for result in get_knowledge\n",
    "    ]\n",
    "    \n",
    "    # Convert to DataFrame for GPT and display\n",
    "    search_results_df = pd.DataFrame([item.dict() for item in search_results_models])\n",
    "    \n",
    "    # Step 3: Generate system response using GPT\n",
    "    print(\"\\n🤖 Generating recommendation with GPT...\\n\")\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an Airbnb listing recommendation system.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Answer this user query: {query} with the following context:\\n{search_results_df}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    system_response = completion.choices[0].message.content\n",
    "    \n",
    "    # Step 4: Display results\n",
    "    print(f\"━\" * 80)\n",
    "    print(f\"❓ USER QUESTION:\")\n",
    "    print(f\"{query}\\n\")\n",
    "    print(f\"━\" * 80)\n",
    "    print(f\"🤖 RECOMMENDATION:\")\n",
    "    print(f\"{system_response}\\n\")\n",
    "    print(f\"━\" * 80)\n",
    "    print(f\"📋 SOURCE DATA:\")\n",
    "    display(HTML(search_results_df.to_html()))\n",
    "    \n",
    "    return system_response\n",
    "\n",
    "print(\"✅ Complete query handler ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Test Full System with Natural Language Query\n",
    "query = \"\"\"\n",
    "I want to stay in a place that's warm and friendly, \n",
    "and not too far from restaurants. Can you recommend a place? \n",
    "Include a reason as to why you've chosen your selection.\n",
    "\"\"\"\n",
    "\n",
    "handle_user_query(query, db, collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
